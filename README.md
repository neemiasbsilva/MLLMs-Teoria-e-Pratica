# Grandes Modelos de Linguagem Multimodais (MLLMs): Da Teoria √† Pr√°tica

[![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?&style=flat&logo=PyTorch&logoColor=white)](https://pytorch.org/)
[![Hugging Face](https://img.shields.io/badge/Hugging%20Face-%F0%9F%A4%97-yellow)](https://huggingface.co/)
[![LangGraph](https://img.shields.io/badge/LangGraph-black?style=flat&logo=langchain&logoColor=white)](https://langchain-ai.github.io/langgraph/)

## Sobre o Evento (WebMedia 2025)

Realizado anualmente pela Sociedade Brasileira de Computa√ß√£o (SBC), o Simp√≥sio Brasileiro de Sistemas Multimodais e Web (WebMedia) √© o principal evento do tema no Brasil e uma excelente oportunidade de interc√¢mbios cient√≠fico e t√©cnico entre alunos, pesquisadores e profissionais das √°reas de Multim√≠dia, Hiperm√≠dia e Web.

Em 2025, especialmente, estaremos celebrando a 31¬™ edi√ß√£o do WebMedia, com organiza√ß√£o da Pontif√≠cia Universidade Cat√≥lica do Rio de Janeiro (PUC-Rio) e do Instituto Militar de Engenharia (IME).

---

> üìå **Nota de Publica√ß√£o Futura**
>¬†
> Este reposit√≥rio serve como material de apoio pr√°tico para o minicurso. Informamos que um material te√≥rico completo, detalhando os conceitos e m√©todos aqui aplicados, ser√° publicado futuramente. Este material servir√° como refer√™ncia e o bibtext estar√° neste README dispon√≠vel.

Este reposit√≥rio cont√©m os *notebooks* desenvolvidos como exemplos pr√°ticos para o minicurso "MLLMs: Teoria e Pr√°tica", apresentado durante o **[WebMedia 2025](https://webmedia.org.br/2025/)** na PUC-RIO.

O objetivo √© fornecer guias pr√°ticos sobre como aplicar Modelos de Linguagem Multimodais (MLLMs) em diferentes tarefas, como classifica√ß√£o de sentimentos e *fine-tuning*.

## Como Executar

Todos os *notebooks* foram desenvolvidos para execu√ß√£o direta na plataforma [Google Colab](https://colab.google/). Basta clicar no emblema "Open in Colab" correspondente ao caso de uso que voc√™ deseja explorar.

## Notebooks Pr√°ticos

### 1. Classifica√ß√£o de Sentimentos com DeepseekVL

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/neemiasbsilva/MLLMs-Teoria-e-Pratica/blob/main/use-cases/Classify_Sentiment_DeepseekVL.ipynb)

* **Arquivo:** `use-cases/Classify_Sentiment_DeepseekVL.ipynb`
* **Descri√ß√£o:** Um tutorial sobre o uso de MLLMs para infer√™ncia de sentimentos em imagens. Aborda a configura√ß√£o do ambiente, carregamento do modelo (DeepseekVL), inicializa√ß√£o do *tokenizer*, e testes de infer√™ncia (√∫nica e em *batch*).

![Classifica√ß√£o de Sentimentos](imagens/SentimentAnalysis.png)

### 2. Fine-tuning de MLLMs com ModernBERT

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/neemiasbsilva/MLLMs-Teoria-e-Pratica/blob/main/use-cases/FineTuning_ModernBERT.ipynb)

* **Arquivo:** `use-cases/FineTuning_ModernBERT.ipynb`
* **Descri√ß√£o:** Um guia para o processo de *fine-tuning* de MLLMs (usando o modelo ModernBERT) para a tarefa de classifica√ß√£o de sentimento. Cobre a cria√ß√£o de arquivos de configura√ß√£o, prepara√ß√£o de dados, *setup* do modelo e a execu√ß√£o do treinamento.

<img src="imagens/mllmsent.png" title="MLLMSent"/>
<img src="imagens/FineTuning.png" title="Fine Tuning"/>

### 3. Identifica√ß√£o de Objetos (Adapta√ß√£o de Prompt)

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/neemiasbsilva/MLLMs-Teoria-e-Pratica/blob/main/use-cases/IdentifyFeatures.ipynb)

* **Arquivo:** `use-cases/IdentifyFeatures.ipynb`
* **Descri√ß√£o:** Este *notebook* introduz uma simples adapta√ß√£o da tarefa de classifica√ß√£o para a identifica√ß√£o de objetos. A diferen√ßa principal est√° na estrutura√ß√£o do *prompt*, que busca obter uma sa√≠da estruturada para facilitar o processamento.

<figure>
<img src="imagens/ImageClassification.png" title="Classifica√ß√£o de Imagens"/>
<figcaption>Cr√©dito: Imagem de Sebastian Raschka</figcaption>
</figure>

### 4. RAG com LangGraph

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/neemiasbsilva/MLLMs-Teoria-e-Pratica/blob/main/use-cases/agent_rag_langgraph.ipynb)

* **Arquivo:** `use-cases/agent_rag_langgraph.ipynb`
* **Descri√ß√£o:** Um *notebook* demonstrando a implementa√ß√£o de um pipeline de RAG (Retrieval-Augmented Generation) utilizando a biblioteca LangGraph para orquestrar o fluxo de dados e estados.

![Pipeline RAG com LangGraph](imagens/pipeline-mllm.png)

---
