{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPYstNa0YPr9mbdwX3hS2HG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neemiasbsilva/MLLMs-Teoria-e-Pratica/blob/main/use-cases/FineTuning_ModernBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning do ModernBERT para Classificação de Sentimento\n",
        "\n",
        "Este notebook guia você pelo processo de fine-tuning de um modelo textual (`answerdotai/ModernBERT-large`) para uma tarefa de classificação de sentimento. Usaremos os scripts fornecidos, adaptados para o ambiente Colab, e adicionaremos o monitoramento de métricas com o TensorBoard.\n",
        "\n",
        "Para mais informações pode consultar o pipeline original no seguinte repositório: [MLLMsent-framework](https://github.com/neemiasbsilva/MLLMsent-framework/tree/main)."
      ],
      "metadata": {
        "id": "0I5gNEZYJyDY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuração do Ambiente\n",
        "\n",
        "Primeiro, vamos instalar as bibliotecas necessárias.\n",
        "\n",
        "- `transformers`, `datasets`, `peft`, `trl`: Essenciais para lidar com os modelos.\n",
        "- `scikit-learn`: Para métricas.\n",
        "- `pyaml`: Para carregar o arquivo de configuração.\n",
        "- `gdown`: Para baixar o dataset do Google Drive.\n",
        "- `tensorboard`: Para o monitoramente."
      ],
      "metadata": {
        "id": "9b5UwqnMKUb9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qs-3INzqUkhU"
      },
      "outputs": [],
      "source": [
        "!pip install transformers[torch] datasets scikit-learn pyyaml gdown tensorboard -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importações dos Pacotes\n",
        "\n",
        "Agora, vamos importar todos os módulos que usaremos no projeto."
      ],
      "metadata": {
        "id": "vUCU_4pwLC9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import yaml\n",
        "import gdown\n",
        "from tqdm.notebook import tqdm\n",
        "from scipy import stats\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter  # Importa o TensorBoard\n",
        "from torch.optim import AdamW\n",
        "\n",
        "# Imports da Hugging Face\n",
        "from transformers import (\n",
        "    AutoModel,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments\n",
        ")\n",
        "\n",
        "# Imports do Scikit-learn\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "5Ja1s-KmLB6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criação do Arquivo de Configuração\n",
        "\n",
        "Vamos criar o arquivo `config.yaml`e os diretórios necessários para os logs e checkpoints, conforme especificado.\n"
      ],
      "metadata": {
        "id": "3lcHbrjULVkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar os diretórios\n",
        "!mkdir -p experiments-finetuning/openai-modernbert-experiment-p3-alpha3/logs\n",
        "!mkdir -p checkpoints\n",
        "\n",
        "# Definir o conteúdo do YAML\n",
        "config_content = \"\"\"\n",
        "experiment_name: \"Experiment Using Moder BERT\"\n",
        "learning_rate: 1e-5\n",
        "batch_size: 4\n",
        "epochs: 5\n",
        "model_path: \"answerdotai/ModernBERT-large\"\n",
        "max_len: 512\n",
        "model_name: \"modern-bert\"\n",
        "log_dir: \"experiments-finetuning/openai-modernbert-experiment-p3-alpha3/logs\"\n",
        "checkpoint_dir: \"checkpoints\"\n",
        "\"\"\"\n",
        "\n",
        "# Escrever o arquivo config.yaml\n",
        "config_path = \"experiments-finetuning/openai-modernbert-experiment-p3-alpha3/config.yaml\"\n",
        "with open(config_path, \"w\") as f:\n",
        "    f.write(config_content)\n",
        "\n",
        "# Função para carregar o config (de utils.other_utils)\n",
        "def load_config(config_path):\n",
        "    \"\"\"Carrega o arquivo de configuração YAML.\"\"\"\n",
        "    with open(config_path, \"r\") as file:\n",
        "        config = yaml.safe_load(file)\n",
        "    print(f\"Configuração carregada de: {config_path}\")\n",
        "    return config\n",
        "\n",
        "# Carregar a configuração para verificar\n",
        "config = load_config(config_path)\n",
        "print(config)"
      ],
      "metadata": {
        "id": "hD3fWSa4LTr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carregamento e Preparação dos Dados\n",
        "\n",
        "Vamos baixar o dataset do Google Drive e prepará-lo. O Script `train` espera uma estrutura de pastas específicas (`data/{dataset_type}/...`). Vamos criar essa estrutura e baixar o arquivo para o local correto.\n",
        "\n"
      ],
      "metadata": {
        "id": "ari6bvOuLizv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar a estrutura de diretório que o script espera\n",
        "# Com base no config_path, o script vai gerar:\n",
        "# dataset_type = \"gpt4-openai-classify\"\n",
        "# alpha_version = 3\n",
        "# experiment_group = \"p3\"\n",
        "# Path final: \"data/gpt4-openai-classify/percept_dataset_alpha3_p3.csv\"\n",
        "\n",
        "data_dir = \"data/gpt4-openai-classify\"\n",
        "data_file_path = os.path.join(data_dir, \"percept_dataset_alpha3_p3.csv\")\n",
        "!mkdir -p {data_dir}\n",
        "\n",
        "# Baixar o arquivo do Google Drive\n",
        "gdrive_url = \"https://drive.google.com/file/d/1a2XrWeXHTjLR_5zWoiK4tsIY-p23iqxO/view?usp=share_link\"\n",
        "gdrive_id = \"1a2XrWeXHTjLR_5zWoiK4tsIY-p23iqxO\"\n",
        "print(f\"Baixando dataset para: {data_file_path}\")\n",
        "gdown.download(id=gdrive_id, output=data_file_path, quiet=False)\n",
        "\n",
        "# Funções de carregamento de dados (do script)\n",
        "def load_dataframe(file_path):\n",
        "    \"\"\"Carrega um dataset de um arquivo CSV.\"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        print(f\"Dataset carregado com sucesso de: {file_path}\")\n",
        "        return df\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Erro: Arquivo não encontrado em {file_path}\")\n",
        "        return None\n",
        "\n",
        "def load_experiment_data(alpha_version, dataset_type, experiment_group):\n",
        "    \"\"\"Carrega o dataset dinamicamente.\"\"\"\n",
        "    file_path = f\"data/{dataset_type}/percept_dataset_alpha{alpha_version}_{experiment_group}.csv\"\n",
        "    df = load_dataframe(file_path)\n",
        "    return df"
      ],
      "metadata": {
        "id": "FehBN1B3Lg5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definição do DataLoader\n",
        "\n",
        "Vamos criar uma implementação padrão do PyTorch (Dataset + DataLoader) que se encaixa no loop de treino."
      ],
      "metadata": {
        "id": "xstU3ID9MZWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSentimentDataset(Dataset):\n",
        "    \"\"\"Dataset customizado para classificação de sentimento.\"\"\"\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.text = dataframe.text.values\n",
        "        self.targets = dataframe.sentiment.values\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
        "            'mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
        "            'token_type_id': torch.tensor(inputs['token_type_ids'], dtype=torch.long),\n",
        "            'targets': torch.tensor(self.targets[index], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "def data_loader(df, tokenizer, max_len, params):\n",
        "    \"\"\"\n",
        "    Cria uma instância do DataLoader.\n",
        "    \"\"\"\n",
        "    dataset = CustomSentimentDataset(df, tokenizer, max_len)\n",
        "    return DataLoader(dataset, **params)"
      ],
      "metadata": {
        "id": "mFPur5lHMVWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definição do Modelo"
      ],
      "metadata": {
        "id": "6H5GKnWhORkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModernBERTModel(torch.nn.Module):\n",
        "    \"\"\"Classe do modelo ModernBERT com uma cabeça de classificação customizada.\"\"\"\n",
        "    def __init__(self, model_id, class_size):\n",
        "        super().__init__()\n",
        "        self.model_id = model_id\n",
        "        self.model = AutoModel.from_pretrained(model_id)\n",
        "\n",
        "        # Adiciona um classificador customizado\n",
        "        self.classifier = torch.nn.Sequential(\n",
        "            torch.nn.Linear(self.model.config.hidden_size, 1024),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(1024, class_size),\n",
        "        )\n",
        "\n",
        "    def forward(self, ids, mask, token_type_id=None):\n",
        "        # Passa a entrada pelo modelo pré-treinado\n",
        "        # O ModernBERT (baseado em BERT) aceita token_type_ids\n",
        "        output = self.model(ids, attention_mask=mask)\n",
        "        last_hidden_state = output.last_hidden_state\n",
        "\n",
        "        # Usa o token [CLS] (posição 0) para classificação\n",
        "        CLS_token_state = last_hidden_state[:, 0, :]\n",
        "        out = self.classifier(CLS_token_state)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "Fg31Nxt4OlcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funções Uteis de Treino e Avaliação"
      ],
      "metadata": {
        "id": "BT9rLCtqMvyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funções de cálculo de métricas e perdas\n",
        "def compute_loss(outputs, targets, loss_fn, model_name):\n",
        "    return loss_fn(outputs, targets)\n",
        "\n",
        "def compute_metrics(preds, targets):\n",
        "    accuracy = accuracy_score(targets, preds)\n",
        "    f1 = f1_score(targets, preds, average=\"weighted\")\n",
        "    return accuracy, f1\n",
        "\n",
        "# Funções de loop de época (train/val)\n",
        "\n",
        "def train_one_epoch(model, train_dl, optimizer, loss_fn, device, model_name):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    preds, targets = [], []\n",
        "\n",
        "    for _, data in enumerate(tqdm(train_dl, desc=\"Treinando Época\", leave=False)):\n",
        "        ids = data[\"ids\"].to(device)\n",
        "        mask = data[\"mask\"].to(device)\n",
        "        targets_batch = data[\"targets\"].to(device)\n",
        "        # token_type_id = data[\"token_type_id\"].to(device) # Removido\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # outputs = model(ids, mask, token_type_id) # Original\n",
        "        outputs = model(ids, mask) # Modificado\n",
        "\n",
        "        loss = compute_loss(outputs, targets_batch, loss_fn, model_name)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        preds.extend(torch.argmax(outputs, axis=1).tolist())\n",
        "        targets.extend(targets_batch.tolist())\n",
        "\n",
        "    return total_loss, preds, targets\n",
        "\n",
        "def validate_one_epoch(model, val_dl, loss_fn, device, model_name):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    preds, targets = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(tqdm(val_dl, desc=\"Validando\", leave=False)):\n",
        "            ids = data[\"ids\"].to(device)\n",
        "            mask = data[\"mask\"].to(device)\n",
        "            targets_batch = data[\"targets\"].to(device)\n",
        "            # token_type_id = data[\"token_type_id\"].to(device) # Removido\n",
        "\n",
        "            # outputs = model(ids, mask, token_type_id) # Original\n",
        "            outputs = model(ids, mask) # Modificado\n",
        "\n",
        "            loss = compute_loss(outputs, targets_batch, loss_fn, model_name)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            preds.extend(torch.argmax(outputs, axis=1).tolist())\n",
        "            targets.extend(targets_batch.tolist())\n",
        "\n",
        "    return total_loss, preds, targets\n",
        "\n",
        "# Funções de logging e checkpoint\n",
        "def save_checkpoint(model, checkpoint_dir, name_arch, experiment_group, alpha_version, fine_tuning, f1_val, best_f1score):\n",
        "    if f1_val > best_f1score:\n",
        "        best_f1score = f1_val\n",
        "        checkpoint_path = os.path.join(\n",
        "            checkpoint_dir, f\"best_checkpoint_{name_arch.split('/')[0]}_{experiment_group}_sigma{alpha_version}_{fine_tuning}.pt\"\n",
        "        )\n",
        "        torch.save(model.state_dict(), checkpoint_path)\n",
        "        print(f\"Checkpoint salvo em: {checkpoint_path} com F1-score: {f1_val:.4f}\")\n",
        "    return best_f1score\n",
        "\n",
        "def log_metrics(epoch, epochs, train_loss, train_accuracy, train_f1, val_loss, val_accuracy, val_f1, log_file):\n",
        "    log_entry = (\n",
        "        f\"Epoch {epoch+1}/{epochs}: \\n\"\n",
        "        f\"Train Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f}, \"\n",
        "        f\"F1-score: {train_f1:.4f}\\n\"\n",
        "        f\"Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}, \"\n",
        "        f\"F1-score: {val_f1:.4f}\\n\"\n",
        "    )\n",
        "    print(log_entry) # Imprime no console do Colab\n",
        "    with open(log_file, \"a\") as f:\n",
        "        f.write(log_entry)\n",
        "\n",
        "# Funções de validação final (pós-treino)\n",
        "def compute_val_loss_and_preds(model, dataloader, loss_fn, device, model_name):\n",
        "    total_loss = 0.0\n",
        "    preds, targets = [], []\n",
        "    model.eval() # Garante que o modelo está em modo de avaliação\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(dataloader):\n",
        "            ids = data[\"ids\"].to(device)\n",
        "            mask = data[\"mask\"].to(device)\n",
        "            targets_batch = data[\"targets\"].to(device)\n",
        "            # token_type_id = data[\"token_type_id\"].to(device) # Removido\n",
        "\n",
        "            # outputs = model(ids, mask, token_type_id) # Original\n",
        "            outputs = model(ids, mask) # Modificado\n",
        "\n",
        "            loss = loss_fn(outputs, targets_batch)\n",
        "            total_loss += loss.item()\n",
        "            preds.extend(torch.argmax(outputs, axis=1).tolist())\n",
        "            targets.extend(targets_batch.tolist())\n",
        "    return total_loss, preds, targets\n",
        "\n",
        "def compute_val_metrics(preds, targets, total_loss, dataloader):\n",
        "    accuracy = accuracy_score(targets, preds)\n",
        "    f1 = f1_score(targets, preds, average=\"weighted\")\n",
        "    loss = total_loss / len(dataloader)\n",
        "    return accuracy, f1, loss\n",
        "\n",
        "def update_metrics_df(df_metrics, kfold, accuracy, f1, start_time):\n",
        "    new_metrics = pd.DataFrame({\n",
        "        \"kfold\": [kfold + 1],\n",
        "        \"accuracy\": [accuracy],\n",
        "        \"f1_score\": [f1],\n",
        "        \"time\": [int(time.time()-start_time)]\n",
        "    })\n",
        "    df_metrics = pd.concat([df_metrics, new_metrics], axis=0)\n",
        "    return df_metrics\n",
        "\n",
        "def save_metrics_to_csv(df_metrics, log_dir):\n",
        "    df_metrics.to_csv(os.path.join(log_dir, f\"test_logs.csv\"), index=False)"
      ],
      "metadata": {
        "id": "qCstF8ZFMuqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Função `fit` (Treino) com TensorBoard\n",
        "\n",
        "Esta é a função `fit`principal, modificada para inicializar e usar o `SummaryWriter` do TensorBoard para logar as métricas a cada época."
      ],
      "metadata": {
        "id": "CwDV41X-NBLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def freeze_backbone(model, head_names=(\"classifier\", \"score\", \"lm_head\", \"classification_head\")):\n",
        "    \"\"\"Congela todos os parâmetros, exceto os da camada 'head'.\"\"\"\n",
        "    for child_name, child_module in model.named_children():\n",
        "        if child_name in head_names:\n",
        "            print(f\"Camada '{child_name}' NÃO foi congelada.\")\n",
        "            continue\n",
        "        # Congela este submódulo\n",
        "        for p in child_module.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "def fit(\n",
        "    model, class_weights, epochs, optimizer,\n",
        "    train_dl, val_dl,\n",
        "    log_dir, checkpoint_dir,\n",
        "    name_arch, fold, model_name,\n",
        "    alpha_version, experiment_group,\n",
        "    device\n",
        "):\n",
        "    # Inicializa o TensorBoard Writer para este fold\n",
        "    tb_log_dir = os.path.join(log_dir, f\"fold_{fold+1}\")\n",
        "    writer = SummaryWriter(log_dir=tb_log_dir)\n",
        "    print(f\"Logs do TensorBoard para este fold: {tb_log_dir}\")\n",
        "\n",
        "    loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights, reduction=\"mean\")\n",
        "\n",
        "    patience = 10\n",
        "    if log_dir.split('/')[0] == \"experiments-not-finetuning\":\n",
        "        print(\"Backbone freeze\")\n",
        "        patience = 25\n",
        "        freeze_backbone(model)\n",
        "\n",
        "    torch.manual_seed(42)\n",
        "    np.random.seed(42)\n",
        "\n",
        "    log_file = os.path.join(log_dir, f\"training_logs_{fold+1:02d}.txt\")\n",
        "    open(log_file, 'w').close()\n",
        "\n",
        "    df_metrics = pd.DataFrame([])\n",
        "    best_f1score = 0\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\n--- Época {epoch+1}/{epochs} ---\")\n",
        "        # Fase de Treinamento\n",
        "        train_loss, preds_train, targets_train = train_one_epoch(model, train_dl, optimizer, loss_fn, device, model_name)\n",
        "        accuracy_train, f1_train = compute_metrics(preds_train, targets_train)\n",
        "        train_loss /= len(train_dl)\n",
        "\n",
        "        # Fase de Validação\n",
        "        val_loss, preds_val, targets_val = validate_one_epoch(model, val_dl, loss_fn, device, model_name)\n",
        "        accuracy_val, f1_val = compute_metrics(preds_val, targets_val)\n",
        "        val_loss /= len(val_dl)\n",
        "\n",
        "        # Logar métricas no arquivo de texto\n",
        "        log_metrics(epoch, epochs, train_loss, accuracy_train, f1_train, val_loss, accuracy_val, f1_val, log_file)\n",
        "\n",
        "        # === ADIÇÃO DO TENSORBOARD ===\n",
        "        writer.add_scalar('Loss/train', train_loss, epoch)\n",
        "        writer.add_scalar('Accuracy/train', accuracy_train, epoch)\n",
        "        writer.add_scalar('F1/train', f1_train, epoch)\n",
        "        writer.add_scalar('Loss/validation', val_loss, epoch)\n",
        "        writer.add_scalar('Accuracy/validation', accuracy_val, epoch)\n",
        "        writer.add_scalar('F1/validation', f1_val, epoch)\n",
        "        # ==============================\n",
        "\n",
        "        # Salvar checkpoint (lógica original)\n",
        "        if f1_val > best_f1score:\n",
        "            best_f1score = f1_val\n",
        "            # (A lógica de salvar o checkpoint foi movida para a função `train` principal)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"Paciência: {patience_counter}/{patience}\")\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Parada antecipada: F1-score de validação não melhorou por {patience} épocas.\")\n",
        "            break\n",
        "\n",
        "        # Atualizar DataFrame de métricas\n",
        "        df_metrics = pd.concat(\n",
        "            [df_metrics, pd.DataFrame({\n",
        "                \"epoch\": [epoch + 1],\n",
        "                \"train_accuracy\": [accuracy_train],\n",
        "                \"train_f1_score\": [f1_train],\n",
        "                \"val_accuracy\": [accuracy_val],\n",
        "                \"val_f1_score\": [f1_val],\n",
        "            })],\n",
        "            axis=0\n",
        "        )\n",
        "        df_metrics.to_csv(os.path.join(log_dir, f\"training_logs_{fold+1:02d}.csv\"), index=False)\n",
        "\n",
        "    writer.close() # Fecha o writer do TensorBoard\n",
        "    return model, loss_fn\n",
        "\n",
        "def val(log_dir, model, dataloader, loss_fn, kfold, df_metrics, model_name, device, start_time):\n",
        "    \"\"\"Fase de validação final após o fit.\"\"\"\n",
        "    print(\"\\n--- Fase de Validação Final ---\")\n",
        "    model.eval()\n",
        "    total_loss, preds, targets = compute_val_loss_and_preds(model, dataloader, loss_fn, device, model_name)\n",
        "\n",
        "    accuracy, f1, loss = compute_val_metrics(preds, targets, total_loss, dataloader)\n",
        "    print(f\"Resultados Finais Fold {kfold+1}: Acurácia: {accuracy:.4f}, F1-Score: {f1:.4f}, Perda: {loss:.4f}\")\n",
        "\n",
        "    df_metrics = update_metrics_df(df_metrics, kfold, accuracy, f1, start_time)\n",
        "    save_metrics_to_csv(df_metrics, log_dir)\n",
        "    return df_metrics, preds, targets, f1"
      ],
      "metadata": {
        "id": "NPJPYwMOM_o3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Função `train` Principal\n",
        "\n",
        "Esta é a função principal que orquestra todo o processo, incluindo o K-fold."
      ],
      "metadata": {
        "id": "CNImajJ3NRVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(config, config_path):\n",
        "    print(f'Iniciando experimento: {config[\"experiment_name\"]}')\n",
        "\n",
        "    # Define o dispositivo (GPU se disponível)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Usando dispositivo: {device}\")\n",
        "\n",
        "    # Extrai hiperparâmetros\n",
        "    learning_rate = float(config[\"learning_rate\"])\n",
        "    batch_size = config[\"batch_size\"]\n",
        "    epochs = config[\"epochs\"]\n",
        "    max_len = config[\"max_len\"]\n",
        "    model_path = config[\"model_path\"]\n",
        "    log_dir = config[\"log_dir\"]\n",
        "    checkpoint_dir = config[\"checkpoint_dir\"]\n",
        "    model_name = config[\"model_name\"]\n",
        "\n",
        "    name_arch = model_path.split(\"-\")[0]\n",
        "    alpha_version = int(config_path.split('/')[-2].split('-')[-1][-1]) # 3, 4 or 5\n",
        "    flag_twiter = False # Mantido do seu script original\n",
        "\n",
        "    print(f\"Config path: {config_path}\")\n",
        "    if config_path.split('/')[-2].split('-')[0] == \"openai\":\n",
        "        dataset_type = \"gpt4-openai-classify\"\n",
        "        # (O resto da lógica de twitter foi mantido, mas não será ativado por este config)\n",
        "    elif config_path.split('/')[-2].split('-')[0] == \"deepseek\":\n",
        "        dataset_type = \"deepseek\"\n",
        "    else:\n",
        "        dataset_type = \"minigpt4-classify\"\n",
        "\n",
        "    experiment_group = config_path.split('/')[-2].split('-')[-2]\n",
        "    print(f\"Alpha version: {alpha_version} | Experiment group: {experiment_group}\")\n",
        "\n",
        "    df = load_experiment_data(alpha_version, dataset_type, experiment_group)\n",
        "\n",
        "    if df is None:\n",
        "        print(\"Falha ao carregar o dataset. Abortando.\")\n",
        "        return\n",
        "\n",
        "    print(\"Preview do Dataset:\")\n",
        "    print(df.head())\n",
        "    print(f\"Classes: {df.sentiment.unique()}\")\n",
        "    print(f\"Distribuição:\\n{df.sentiment.value_counts()}\")\n",
        "\n",
        "    train_val_df = df.copy()\n",
        "    train_params = {\"batch_size\": batch_size, \"shuffle\": True}\n",
        "    val_params = {\"batch_size\": batch_size, \"shuffle\": False}\n",
        "\n",
        "    # Correção: O seu script tinha um 'elif' solto, mudei para 'if'\n",
        "    if model_name == \"modern-bert\":\n",
        "        kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "        df_metrics = pd.DataFrame([])\n",
        "        best_f1 = 0\n",
        "\n",
        "        for fold, (train_idx, val_idx) in enumerate(kfold.split(train_val_df)):\n",
        "            print(f\"\\n========== FOLD {fold + 1} / 5 ==========\")\n",
        "            print(f\"Carregando modelo: {model_path}\")\n",
        "            start_time = time.time()\n",
        "\n",
        "            model = ModernBERTModel(model_path, len(df.sentiment.unique()))\n",
        "            tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "            model.to(device)\n",
        "\n",
        "            optimizer = AdamW(\n",
        "                model.parameters(),\n",
        "                lr=learning_rate,\n",
        "                weight_decay=1e-6\n",
        "            )\n",
        "\n",
        "            train_df = train_val_df.iloc[train_idx].reset_index(drop=True)\n",
        "            val_df = train_val_df.iloc[val_idx].reset_index(drop=True)\n",
        "\n",
        "            # (A lógica do 'flag_twiter' para o val_df foi mantida aqui)\n",
        "            if flag_twiter:\n",
        "                print(\"Lógica específica do Twitter ativada para validação...\")\n",
        "                # ... (seu código original de carregamento do val_df do twitter) ...\n",
        "                pass\n",
        "\n",
        "            # Calcular pesos das classes\n",
        "            class_size = train_df.sentiment.value_counts().sort_index().to_list()\n",
        "            class_weights = torch.Tensor([sum(class_size) / c for c in class_size]).to(device) # Normalizado\n",
        "            print(f\"Pesos das classes: {class_weights}\")\n",
        "\n",
        "            train_dl = data_loader(train_df, tokenizer, max_len, train_params)\n",
        "            val_dl = data_loader(val_df, tokenizer, max_len, val_params)\n",
        "\n",
        "            model, loss_fn = fit(\n",
        "                model, class_weights, epochs, optimizer,\n",
        "                train_dl, val_dl,\n",
        "                log_dir, checkpoint_dir,\n",
        "                name_arch, fold, model_name,\n",
        "                alpha_version, experiment_group,\n",
        "                device\n",
        "            )\n",
        "\n",
        "            df_metrics, y_pred, y_true, f1_val = val(log_dir, model, val_dl, loss_fn, fold, df_metrics, model_name, device, start_time)\n",
        "\n",
        "            fine_tuning = \"finetuned\" if log_dir.split('/')[0] != \"experiments-not-finetuning\" else \"not_finetuned\"\n",
        "            current_name_arch = dataset_type + \"_modernbert\"\n",
        "\n",
        "            # Salvar o melhor checkpoint *entre os folds*\n",
        "            if f1_val > best_f1:\n",
        "                print(f\"Novo melhor F1-score global: {f1_val:.4f} (anterior: {best_f1:.4f})\")\n",
        "                best_f1 = save_checkpoint(model, checkpoint_dir, current_name_arch, experiment_group, alpha_version, fine_tuning, f1_val, best_f1)\n",
        "\n",
        "            # Salvar predições\n",
        "            result_df = pd.DataFrame({\n",
        "                \"text\": val_df[\"text\"].to_list(),\n",
        "                \"target\": y_true,\n",
        "                \"prediction\": y_pred\n",
        "            })\n",
        "            result_df.to_csv(os.path.join(log_dir, f\"test_logs_fold_{fold+1:02d}.csv\"), index=False)\n",
        "\n",
        "            del model # Limpar memória da GPU\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        # Calcular métricas finais\n",
        "        mean_f1 = np.mean(df_metrics[\"f1_score\"].to_numpy())\n",
        "        std_f1 = np.std(df_metrics[\"f1_score\"].to_numpy())\n",
        "\n",
        "        print(\"\\n========== RESULTADO FINAL (K-Fold) ==========\")\n",
        "        print(f\"F1-Score Médio: {mean_f1 * 100:.2f}% ± {std_f1 * 100:.2f}%\")\n",
        "        print(\"Métricas por fold:\")\n",
        "        print(df_metrics)\n",
        "\n",
        "    else:\n",
        "        print(f\"Modelo '{model_name}' não suportado por este script.\")"
      ],
      "metadata": {
        "id": "ixyPWE25NQaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inicial o TensorBoard\n",
        "\n",
        "Vamos carregar a extensão do TensorBoard no Colab. Ele ficará monitorando o diretório de logs"
      ],
      "metadata": {
        "id": "z57MIxzqNdnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar a extensão do TensorBoard\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Iniciar o TensorBoard\n",
        "# Ele vai monitorar o diretório de logs que definimos no config.yaml\n",
        "%tensorboard --logdir experiments-finetuning/openai-modernbert-experiment-p3-alpha3/logs"
      ],
      "metadata": {
        "id": "Jii7iyr2NdE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Executar o Treinamento\n",
        "\n",
        "Finalmente, executamos a função `train`. O TensorBoard (célula acima) será atualizada automaticamente à medida que os logs forem escritos durante o treinamento."
      ],
      "metadata": {
        "id": "l_b2wpLZNpQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir o path do config (já o criamos)\n",
        "config_path = \"experiments-finetuning/openai-modernbert-experiment-p3-alpha3/config.yaml\"\n",
        "\n",
        "# Carregar o config\n",
        "config = load_config(config_path)\n",
        "\n",
        "# Iniciar o treinamento\n",
        "train(config, config_path)"
      ],
      "metadata": {
        "id": "gkOM7aZfNn1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GHqwDFH5N6ic"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}